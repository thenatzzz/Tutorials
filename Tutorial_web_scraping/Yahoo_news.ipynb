{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import csv \n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'https://ca.search.yahoo.com/search?p={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = template.format('iphone 12 leaked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'accept': '*/*',\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "    'referer': 'https://www.google.com',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36 Edg/85.0.564.44'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url,headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cards = soup.find_all('div',\"dd algo algo-sr relsrch Sr\")\n",
    "cards = soup.find_all('div',re.compile(\"dd algo algo-sr\"))\n",
    "# cards = soup.find_all('div',{'class':re.compile(\"dd algo\")})\n",
    "\n",
    "len(cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a prototype model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card = cards[8]\n",
    "card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline=card.find('h3','title').text\n",
    "headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source=card.find('span','fz-ms').text\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time=card.find('span','fc-2nd').text.replace('·','').strip()\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description=card.find('p','fz-ms').text.strip()\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_tag = 'fz-ms fw-m fc-12th wr-bw lh-17'\n",
    "raw_link=card.find('span',url_tag).text#.replace('·','').strip()\n",
    "raw_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(card):\n",
    "    '''Extract article info from the raw html'''\n",
    "    headline=card.find('h3','title').text\n",
    "    source=card.find('span','fz-ms').text\n",
    "    try:\n",
    "        time=card.find('span','fc-2nd').text.replace('·','').strip()\n",
    "    except AttributeError:\n",
    "        time =''\n",
    "    description=card.find('p','fz-ms').text.strip()\n",
    "    \n",
    "    url_tag = 'fz-ms fw-m fc-12th wr-bw lh-17'\n",
    "    raw_link=card.find('span',url_tag).text#.replace('·','').strip()\n",
    "\n",
    "    article = (headline,source,time,description,raw_link)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "# to avoid duplicate\n",
    "links = set()\n",
    "\n",
    "for card in cards:\n",
    "    article = get_article(card)\n",
    "#     print(article)\n",
    "    link = article[-1]\n",
    "    if not link in links:\n",
    "        links.add(link)\n",
    "        articles.append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = soup.find('a','next').get('href')\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import csv \n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'accept': '*/*',\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "    'referer': 'https://www.google.com',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36 Edg/85.0.564.44'\n",
    "}\n",
    "\n",
    "def get_article(card):\n",
    "    '''Extract article info from the raw html'''\n",
    "    headline=card.find('h3','title').text\n",
    "    source=card.find('span','fz-ms').text\n",
    "    try:\n",
    "        time=card.find('span','fc-2nd').text.replace('·','').strip()\n",
    "    except:\n",
    "        time =''\n",
    "    description=card.find('p','fz-ms').text.strip()\n",
    "    \n",
    "    url_tag = 'fz-ms fw-m fc-12th wr-bw lh-17'\n",
    "    raw_link=card.find('span',url_tag).text#.replace('·','').strip()\n",
    "\n",
    "    article = (headline,source,time,description,raw_link)\n",
    "    return article\n",
    "\n",
    "\n",
    "def get_the_news(search):\n",
    "    '''Run the main program'''\n",
    "    template = 'https://ca.search.yahoo.com/search?p={}'\n",
    "    url = template.format(search) \n",
    "    \n",
    "    articles = []\n",
    "    links = set()\n",
    "    i = 0\n",
    "    while True:\n",
    "        response = requests.get(url,headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        cards = soup.find_all('div',re.compile(\"dd algo algo-sr\"))\n",
    "    \n",
    "        for card in cards:\n",
    "            article = get_article(card)\n",
    "        #     print(article)\n",
    "            link = article[-1]\n",
    "            if not link in links:\n",
    "                links.add(link)\n",
    "                articles.append(article)\n",
    "                \n",
    "        # find the next page\n",
    "        try:\n",
    "            url = soup.find('a','next').get('href')\n",
    "            print(url)\n",
    "            sleep(1)\n",
    "        except AttributeError:\n",
    "            break\n",
    "        i += 1\n",
    "        print(i)\n",
    "        if i ==5:\n",
    "            break\n",
    "\n",
    "\n",
    "    # save articles data\n",
    "    with open('results_yahoo.csv','w',newline='',encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Headline','Source','Posted','Description','Link'])\n",
    "        writer.writerows(articles)\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ca.search.yahoo.com/search;_ylt=AwrgEa9BEvpftG0A.X3rFAx.;_ylu=Y29sbwNncTEEcG9zAzEEdnRpZAMEc2VjA3BhZ2luYXRpb24-?p=iphone+12+leaked&b=11&pz=10&pstart=5\n",
      "1\n",
      "https://ca.search.yahoo.com/search;_ylt=Awr9J.1DEvpfmrgAGrfrFAx.;_ylu=Y29sbwNncTEEcG9zAzEEdnRpZAMEc2VjA3BhZ2luYXRpb24-?p=iphone+12+leaked&pz=10&b=21&pz=10&pstart=3\n",
      "2\n",
      "https://ca.search.yahoo.com/search;_ylt=AwrgEa1EEvpf66kAjJbrFAx.;_ylu=Y29sbwNncTEEcG9zAzEEdnRpZAMEc2VjA3BhZ2luYXRpb24-?p=iphone+12+leaked&pz=10&b=31&pz=10&pstart=3\n",
      "3\n",
      "https://ca.search.yahoo.com/search;_ylt=Awr9J.xGEvpfVgoAVyfrFAx.;_ylu=Y29sbwNncTEEcG9zAzEEdnRpZAMEc2VjA3BhZ2luYXRpb24-?p=iphone+12+leaked&pz=10&b=41&pz=10&pstart=3\n",
      "4\n",
      "https://ca.search.yahoo.com/search;_ylt=AwrT4pFHEvpfh44ACZLrFAx.;_ylu=Y29sbwNncTEEcG9zAzEEdnRpZAMEc2VjA3BhZ2luYXRpb24-?p=iphone+12+leaked&pz=10&b=51&pz=10&pstart=3\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "articles = get_the_news('iphone 12 leaked')\n",
    "# articles = get_the_news('nattapat jutha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles[:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tf_gpu15)",
   "language": "python",
   "name": "conda_tf_gpu15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
